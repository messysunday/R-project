---
title: "11E tidying"
---




# libraries 
```{r}
libs <- c("tidyverse")

installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == F)) {
    install.packages(libs[!installed_libs])
}
```

```{r}
library(tidyverse)
```


# Data tidying


## Tidy data


There are three interrelated rules that make a dataset tidy:
1.  Each variable is a column; each column is a variable.
2.  Each observation is a row; each row is an observation.
3.  Each value is a cell; each cell is a single value.


Why ensure that your data is tidy? There are two main advantages:
1.  There’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity.
    
2.  There’s a specific advantage to placing variables in columns because it allows R’s vectorized nature to shine. 

dplyr, ggplot2, and all the other packages in the tidyverse are designed to work with tidy data. 

## Lengthening data

The principles of tidy data might seem so obvious that you wonder if you’ll ever encounter a dataset that isn’t tidy. Unfortunately, however, most real data is untidy. 

There are two main reasons:

1.  Data is often organised to facilitate some goal other than analysis. For example, it’s common for data to be structured to make data entry, not analysis, easy.
    
2.  Most people aren’t familiar with the principles of tidy data, and it’s hard to derive them yourself unless you spend a lot of time working with data.


This means that most real analyses will require at least a little tidying. You’ll begin by figuring out what the underlying variables and observations are. Sometimes this is easy; other times you’ll need to consult with the people who originally generated the data. Next, you’ll **pivot** your data into a tidy form, with variables in the columns and observations in the rows.


tidyr provides two functions for pivoting data: `pivot_longer()` and `pivot_wider()`.


###  Data in column names

The `billboard` dataset records the billboard rank of songs in the year 2000:
```{r}
billboard
```
In this dataset, each observation is a song. The first three columns (`artist`, `track` and `date.entered`) are variables that describe the song. Then we have 76 columns (`wk1`-`wk76`) that describe the rank of the song in each week. Here, the column names are one variable (the `week`) and the cell values are another (the `rank`).


To tidy this data, we’ll use `pivot_longer()`. After the data, there are three key arguments:
-    `cols` specifies which columns need to be pivoted, i.e. which columns aren’t variables. This argument uses the same syntax as `select()` so here we could use `!c(artist, track, date.entered)` or `starts_with("wk")`.
-   `names_to` names of the variable stored in the column names, here `"week"`.
-    `values_to` names the variable stored in the cell values, here `"rank"`.


That gives the following call:
```{r}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
```

What happens if a song is in the top 100 for less than 76 weeks? Take 2 Pac’s “Baby Don’t Cry”, for example. The above output suggests that it was only the top 100 for 7 weeks, and all the remaining weeks are filled in with missing values. These `NA`s don’t really represent unknown observations; they’re forced to exist by the structure of the dataset, so we can ask `pivot_longer()` to get rid of them by setting `values_drop_na = TRUE`:
```{r}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```
This data is now tidy, but we could make future computation a bit easier by converting `week` into a number using `mutate()` and `readr::parse_number()`. `parse_number()` is a handy function that will extract the first number from a string, ignoring all other text.

```{r}
billboard_tidy <- billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  ) %>% 
  mutate(
    week = parse_number(week)
  )

billboard_tidy
```


### Many variables in column names

A more challenging situation occurs when you have multiple variables crammed into the column names. For example, take the `who2` dataset:
```{r}
who2
```

This dataset records information about tuberculosis data collected by the WHO. There are two columns that are already variables and are easy to interpret: `country` and `year`. They are followed by 56 columns like `sp_m_014`, `ep_m_4554`, and `rel_m_3544`.
If you stare at these columns for long enough, you’ll notice there’s a pattern. Each column name is made up of three pieces separated by `_`. The first piece, `sp`/`rel`/`ep`, describes the method used for the `diagnosis`, the second piece, `m`/`f` is the `gender`, and the third piece, `014`/`1524`/`2535`/`3544`/`4554`/`65` is the `age` range.


So in this case we have six variables: two variables are already columns, three variables are contained in the column name, and one variable is in the cell. This requires two changes to our call `pivot_longer()`:
`names_to` gets a vector of column names
and `names_sep` describes how to split the variable name up into pieces:
```{r}
who2 %>% 
  pivot_longer(
    cols = !(country:year),
    names_to = c("diagnosis", "gender", "age"), 
    names_sep = "_",
    values_to = "count"
  )
```

  
An alternative to `names_sep` is `names_pattern`, which you can use to extract variables from more complicated naming scenarios, once you’ve learned about regular expressions.


### Data and variable names in the column headers

The next step up in complexity is when the column names include a mix of variable values and variable names. For example, take the `household` dataset:
```{r}
household
```

This dataset contains data about five families, with the names and dates of birth of up to two children. The new challenge in this dataset is that the column names contain the names of two variables (`dob`, `name)` and the values of another (`child,` with values 1 or 2). To solve this problem we again need to supply a vector to `names_to` but this time we use the special `".value"` sentinel. This overrides the usual `values_to` argument to use the first component of the pivoted column name as a variable name in the output.

```{r}
household %>% 
  pivot_longer(
    cols = !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```

```{r}
household %>% 
  pivot_longer(
    cols = !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  ) %>% 
  mutate(
    child = parse_number(child)
  )

```

## Widening data

So far we’ve used `pivot_longer()` to solve the common class of problems where values have ended up in column names. Next we’ll pivot  to `pivot_wider()`, which which makes datasets **wider** by increasing columns and reducing rows and helps when one observation is spread across multiple rows. This seems to arise less commonly in the wild, but it does seem to crop up a lot when dealing with governmental data.

We’ll start by looking at `cms_patient_experience`, a dataset from the Centers of Medicare and Medicaid services that collects data about patient experiences:
```{r}
cms_patient_experience
```


An observation is an organisation, but each organisation is spread across six rows, with one row for each variable, or measure. We can see the complete set of values for `measure_cd` and `measure_title` by using `distinct()`:

```{r}
cms_patient_experience %>% 
  distinct(measure_cd, measure_title)
```


Neither of these columns will make particularly great variable names: `measure_cd` doesn’t hint at the meaning of the variable and `measure_title` is a long sentence containing spaces. We’ll use `measure_cd` for now, but in a real analysis you might want to create your own variable names that are both short and meaningful.

`pivot_wider()` has the opposite interface to `pivot_longer()`: we need to provide the existing columns that define the values (`values_from`) and the column name (`names_from)`:
```{r}
cms_patient_experience %>% 
  pivot_wider(
    names_from = measure_cd,
    values_from = prf_rate
  )
```


The output doesn’t look quite right; we still seem to have multiple rows for each organization. That’s because, by default, `pivot_wider()` will attempt to preserve all the existing columns including `measure_title` which has six distinct observations for each organisations. To fix this problem we need to tell `pivot_wider()` which columns identify each row; in this case those are the variables starting with `"org"`:
```{r}
cms_patient_experience %>% 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```


## separate(),  separate_wider_position() and separate_wider_delim() 


If you want to split by any non-alphanumeric value (the default):
```{r}
df <- tibble(x = c(NA, "x.y", "x.z", "y.z"))
df
```

```{r}
df %>%
  separate(x, c("A", "B"))
```

If you just want the second variable:
```{r}
df %>%
  separate(x, c(NA, "B"))
```

separate_wider_delim() is now recommended:
```{r}
df %>%
  separate_wider_delim(x, ".", names = c("A", "B"))
```

```{r}
df %>%
  separate_wider_delim(x, ".", names = c(NA, "B"))
```

## Controlling uneven splits

If every row doesn't split into the same number of pieces, use the extra and fill arguments to control what happens:\
```{r}
df <- tibble(x = c("x", "x y", "x y z", NA))
df
```

```{r}
df %>%
  separate(x, c("a", "b"))
```

The same behaviour as previous, but drops the c without warnings:
```{r}
df %>%
  separate(x, c("a", "b"), extra = "drop", fill = "right")
```

Opposite of previous, keeping the c and filling left:
```{r}
df %>%
  separate(x, c("a", "b"), extra = "merge", fill = "left")
```

 Or you can keep all three:
```{r}
df %>%
  separate(x, c("a", "b", "c"))
```
 
To only split a specified number of times use extra = "merge":
```{r}
df <- tibble(x = c("x: 123", "y: error: 7"))
df
```

```{r}
df %>% 
  separate(x, c("key", "value"), ": ", extra = "merge")
```

Controlling column types

convert = TRUE detects column classes:
```{r}
df <- tibble(x = c("x:1", "x:2", "y:4", "z", NA))
df
```

```{r}
df %>%
  separate(x, c("key", "value"), ":") %>%
  str()
```

```{r}
df %>%
  separate(x, c("key", "value"), ":", convert = TRUE) %>%
  str()
```


## unite()

Convenience function to paste together multiple columns into one.
```{r}
df <- expand_grid(x = c("a", NA), y = c("b", NA))
df
```

```{r}
df %>%
  unite("z", x:y, remove = FALSE)
```


To remove missing values:
```{r}
df %>%
  unite("z", x:y, na.rm = TRUE, remove = FALSE)
```

Separate is almost the complement of unite
```{r}
df %>%
  unite("xy", x:y) %>%
  separate(xy, c("x", "y"))
```


